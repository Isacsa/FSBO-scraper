# IntegraÃ§Ã£o Idealista via Lobstr.io

## âœ… ImplementaÃ§Ã£o Completa

Foi criada uma integraÃ§Ã£o completa do Idealista usando a API do Lobstr.io, que utiliza o squid "Idealista Listings Search Export" para fazer crawling completo e retornar resultados estruturados.

## ğŸ“ Estrutura Criada

```
src/scrapers/idealista_lobstr/
â”œâ”€â”€ idealista.client.js     # Cliente Lobstr API (tasks, runs, results)
â”œâ”€â”€ idealista.extract.js    # ExtraÃ§Ã£o via Lobstr (cria task, obtÃ©m results)
â”œâ”€â”€ idealista.parse.js      # Parsing e complementaÃ§Ã£o de dados
â”œâ”€â”€ idealista.normalize.js  # NormalizaÃ§Ã£o para formato FSBO_SCORE
â””â”€â”€ idealista.scraper.js    # Entry-point principal

scripts/
â””â”€â”€ list-lobstr-squids.js   # Script auxiliar para listar squids

tests/
â””â”€â”€ test-idealista-lobstr.js # Testes automÃ¡ticos
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# API Key do Lobstr.io (obrigatÃ³rio)
export LOBSTR_API_KEY="sua-api-key-aqui"

# UUID do squid Idealista (opcional - serÃ¡ detectado automaticamente)
export IDEALISTA_SQUID_ID="707155221624420fb6995f1ba42d1ebf"
```

### Obter UUID do Squid

Execute o script auxiliar para listar squids disponÃ­veis:

```bash
node scripts/list-lobstr-squids.js
```

Isso mostrarÃ¡ todos os squids disponÃ­veis e o UUID do squid Idealista.

## ğŸš€ Uso

### Via API (Controller)

```bash
POST /scrape
{
  "url": "https://www.idealista.pt/comprar-casas/lisboa/",
  "max_results": 10  # opcional, padrÃ£o: 1
}
```

### Diretamente no cÃ³digo

```javascript
const scrapeIdealistaLobstr = require('./src/scrapers/idealista_lobstr/idealista.scraper');

const listings = await scrapeIdealistaLobstr('https://www.idealista.pt/comprar-casas/lisboa/', {
  maxResults: 10,
  maxWait: 300000 // 5 minutos
});
```

## ğŸ“Š Fluxo de Funcionamento

1. **Extract** (`idealista.extract.js`):
   - Cria task no Lobstr com URL de pesquisa
   - Aguarda run iniciar
   - Faz polling atÃ© run completar
   - ObtÃ©m todos os results via paginaÃ§Ã£o

2. **Parse** (`idealista.parse.js`):
   - Infere tipo de imÃ³vel do tÃ­tulo
   - Converte bedrooms para tipologia (T1, T2, etc.)
   - Detecta se Ã© agÃªncia (keywords)
   - Detecta fotos profissionais
   - Normaliza preÃ§os

3. **Normalize** (`idealista.normalize.js`):
   - Monta JSON final no formato FSBO_SCORE
   - Preenche campos obrigatÃ³rios
   - Aplica normalizaÃ§Ã£o final do schema

## ğŸ“‹ Dados Retornados pelo Lobstr

O squid retorna os seguintes campos por listing:

- `id` - ID interno do Lobstr
- `native_id` - ID do anÃºncio no Idealista
- `url` - URL do anÃºncio
- `title` - TÃ­tulo
- `description` - DescriÃ§Ã£o
- `price` - PreÃ§o (nÃºmero)
- `currency` - Moeda
- `area` - Ãrea (mÂ²)
- `bedrooms` - NÃºmero de quartos
- `floor` - Piso
- `main_image` - URL da imagem principal
- `phone` - Telefone (quando disponÃ­vel)
- `scraping_time` - Data/hora do scraping

## ğŸ”„ Campos Derivados

O parser infere os seguintes campos:

- `property.type` - Apartamento, moradia, etc. (do tÃ­tulo)
- `tipology` - T1, T2, T3, etc. (de bedrooms)
- `is_agency` - Detectado por keywords
- `agency_keywords` - Lista de keywords encontradas
- `professional_photos` - HeurÃ­stica baseada em URL da imagem

## âš ï¸ LimitaÃ§Ãµes

- **LocalizaÃ§Ã£o**: Lobstr nÃ£o fornece dados de localizaÃ§Ã£o (district, municipality, parish, lat, lng) - campos ficam `null`
- **Anunciante**: Nome sempre "unknown", total_ads sempre `null`
- **Features**: Array vazio (Lobstr nÃ£o fornece features detalhadas)
- **Datas**: Apenas `published_date` (do scraping_time), `updated_date` sempre `null`
- **Condition**: Sempre `null` (Lobstr nÃ£o fornece)

## ğŸ§ª Testes

Execute os testes automÃ¡ticos:

```bash
node tests/test-idealista-lobstr.js
```

## ğŸ“ Notas Importantes

1. **Runs Abortados**: Se um run for abortado, o sistema lanÃ§arÃ¡ erro. Isso pode acontecer se:
   - O squid nÃ£o estiver configurado corretamente
   - A URL de pesquisa for invÃ¡lida
   - Houver problemas no Lobstr

2. **Polling**: O sistema faz polling a cada 5 segundos atÃ© o run completar (mÃ¡ximo 5 minutos por padrÃ£o)

3. **PaginaÃ§Ã£o**: Results sÃ£o obtidos automaticamente via paginaÃ§Ã£o (100 por pÃ¡gina)

4. **Compatibilidade**: O scraper retorna array de listings, mas o controller retorna apenas o primeiro para compatibilidade com API de anÃºncio individual

## ğŸ”— IntegraÃ§Ã£o com Sistema Existente

- âœ… Integrado no `scrapeController.js`
- âœ… Detectado automaticamente por `detectPlatform()`
- âœ… CompatÃ­vel com n8n
- âœ… Usa `normalizeFinalObject()` para garantir schema
- âœ… Logging estruturado

