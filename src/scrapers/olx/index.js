/**
 * Scraper principal para OLX
 * Orquestra extra√ß√£o, parsing, normaliza√ß√£o e sinais FSBO
 */

const { createBrowser, createPage, navigateWithRetry } = require('../../utils/browser');
const { closePopupsAndOverlays } = require('../helpers');
const extractRawData = require('./extract');
const parseRawData = require('./parse');
const normalizeToFinalFormat = require('./normalize');
// FSBO signals ser√° importado quando necess√°rio
const path = require('path');
const fs = require('fs');

const SESSION_FILE = path.join(__dirname, '../../../olx-session.json');
const PLATFORM = 'olx';

/**
 * Scraper para OLX
 * @param {string} url - URL do an√∫ncio
 * @param {Object} options - Op√ß√µes de scraping
 * @param {boolean} options.headless - Modo headless
 * @param {boolean} options.includeRawHtml - Incluir HTML bruto na resposta
 * @returns {Promise<Object>}
 */
async function scrapeOLX(url, options = {}) {
  const startTime = Date.now();
  const { 
    headless = true, 
    includeRawHtml = false,
    timeout = 30000,
    proxy = null
  } = options;
  
  let browser = null;
  let page = null;

  try {
    console.log(`[${PLATFORM.toUpperCase()}] üöÄ Iniciando scrape para: ${url}`);

    // Verificar se existe sess√£o guardada
    let storageStatePath = null;
    if (fs.existsSync(SESSION_FILE)) {
      try {
        const sessionData = JSON.parse(fs.readFileSync(SESSION_FILE, 'utf8'));
        const hasCookies = sessionData.cookies && sessionData.cookies.length > 0;
        const hasStorage = sessionData.origins && sessionData.origins.length > 0;
        
        if (hasCookies || hasStorage) {
          storageStatePath = SESSION_FILE;
          const stats = fs.statSync(SESSION_FILE);
          console.log(`[${PLATFORM.toUpperCase()}] ‚úÖ Sess√£o guardada encontrada`);
          console.log(`[${PLATFORM.toUpperCase()}] üìÖ Sess√£o criada em: ${stats.mtime.toISOString()}`);
        }
      } catch (error) {
        console.log(`[${PLATFORM.toUpperCase()}] ‚ö†Ô∏è  Erro ao ler ficheiro de sess√£o: ${error.message}`);
      }
    }

      // Criar browser
      console.log(`[${PLATFORM.toUpperCase()}] üöÄ Iniciando browser (headless: ${headless})...`);
      browser = await createBrowser({ headless, timeout, proxy });

    // Criar p√°gina com sess√£o se dispon√≠vel e configura√ß√µes para Portugal
    const pageOptions = {
      timeout,
      storageStatePath: storageStatePath || null,
      locale: 'pt-PT',
      timezoneId: 'Europe/Lisbon',
      geolocation: { latitude: 38.7223, longitude: -9.1393 } // Lisboa
    };
    
    page = await createPage(browser, pageOptions);
    page.setDefaultTimeout(timeout);
    page.setDefaultNavigationTimeout(timeout);
    
    console.log(`[${PLATFORM.toUpperCase()}] ‚úÖ Browser e p√°gina criados com sucesso`);

    // Navegar para a URL do an√∫ncio
    console.log(`[${PLATFORM.toUpperCase()}] üåê Navegando para: ${url}`);
    await navigateWithRetry(page, url);

    // Aguardar carregamento inicial
    await page.waitForTimeout(2000);
    await page.waitForLoadState('networkidle', { timeout: 10000 }).catch(() => {});

    // Fechar popups, overlays e banners
    await closePopupsAndOverlays(page, PLATFORM.toUpperCase());

    // Aguardar um pouco mais para garantir que a p√°gina est√° est√°vel
    await page.waitForTimeout(1000);

    // 1. EXTRAIR DADOS BRUTOS
    console.log(`[${PLATFORM.toUpperCase()}] üì• Fase 1: Extra√ß√£o de dados brutos`);
    const raw = await extractRawData(page, url);

    // 2. PARSEAR E NORMALIZAR CAMPOS
    console.log(`[${PLATFORM.toUpperCase()}] üîß Fase 2: Parsing e normaliza√ß√£o`);
    const parsed = parseRawData(raw);

    // 2.5. NORMALIZAR ANUNCIANTE (visitar perfil se necess√°rio)
    console.log(`[${PLATFORM.toUpperCase()}] üë§ Fase 2.5: Normaliza√ß√£o do anunciante`);
    const { normalizeAdvertiser } = require('../../utils/advertiserNormalizer');
    const normalizedAdvertiser = await normalizeAdvertiser(
      parsed.advertiser,
      PLATFORM,
      page,
      true // visitProfile = true
    );
    parsed.advertiser = normalizedAdvertiser;

    // 3. MONTAR JSON FINAL
    console.log(`[${PLATFORM.toUpperCase()}] üìã Fase 3: Montagem do JSON final`);
    let finalJson = await normalizeToFinalFormat(parsed, url, PLATFORM);

    // 4. ANALISAR SINAIS FSBO
    console.log(`[${PLATFORM.toUpperCase()}] üîç Fase 4: An√°lise de sinais FSBO`);
    const { analyzeFsboSignals } = require('../../services/fsboSignals');
    const signals = analyzeFsboSignals({
      title: finalJson.title,
      description: finalJson.description,
      advertiser: finalJson.advertiser,
      photos: finalJson.photos,
      price: finalJson.price,
      location: finalJson.location
    }, PLATFORM);
    
    finalJson.signals = signals;
    
    // Atualizar is_agency no advertiser com base nos sinais (se ainda n√£o foi definido)
    if (finalJson.advertiser.is_agency === null || finalJson.advertiser.is_agency === undefined) {
      finalJson.advertiser.is_agency = signals.is_agency;
    }
    
    // 5. NORMALIZA√á√ÉO FINAL (garantir schema)
    console.log(`[${PLATFORM.toUpperCase()}] ‚ú® Fase 5: Normaliza√ß√£o final do schema`);
    const { normalizeFinalObject } = require('../../utils/finalNormalizer');
    finalJson = normalizeFinalObject(finalJson);

    // Incluir HTML bruto se solicitado (ap√≥s normaliza√ß√£o, ser√° removido pelo normalizer)
    if (includeRawHtml) {
      finalJson.rawHtml = await page.content();
    }

    console.log(`[${PLATFORM.toUpperCase()}] ‚úÖ Scrape conclu√≠do com sucesso!`);
    
    // Retornar apenas os dados (sem success, ser√° adicionado pelo controller)
    return finalJson;

  } catch (error) {
    console.error(`[${PLATFORM.toUpperCase()}] ‚ùå Erro durante o scrape:`, error);
    // Re-throw para ser tratado pelo controller
    throw error;
  } finally {
    if (page) await page.close().catch(() => {});
    if (browser) await browser.close().catch(() => {});
  }
}

module.exports = scrapeOLX;

